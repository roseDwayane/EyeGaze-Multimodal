# ViT Configuration for Single vs Competition Classification
# Using Hugging Face Transformers

# Model Configuration
model:
  model_type: "dual"  # "single" or "dual" - dual for fused player1+player2
  model_name: "google/vit-base-patch16-224"
  num_labels: 3  # Single, Competition, Cooperation
  image_size: 224  # Size for each individual image
  pretrained: true
  freeze_backbone: false
  concat_mode: "subtract"  # Fusion mode: "horizontal", "vertical", "add", "multiply", "subtract"

# Data Configuration
data:
  metadata_path: "Data/metadata/complete_metadata.json"
  image_base_path: "G:/共用雲端硬碟/CNElab_林佳誼_Gaze/B.GazeImage/01.data/bgOn_heatmapOn_trajOn"
  train_test_split: 0.2  # 2% for test set
  random_seed: 42

  # Image preprocessing
  image_size: 224
  normalize_mean: [0.485, 0.456, 0.406]  # ImageNet stats
  normalize_std: [0.229, 0.224, 0.225]

  # Class mapping
  class_names: ["Single", "Competition", "Cooperation"]
  label2id:
    "Single": 0
    "Competition": 1
    "Cooperation": 2
  id2label:
    0: "Single"
    1: "Competition"
    2: "Cooperation"

# Training Configuration (Following Hugging Face Trainer)
training:
  output_dir: "Experiments/outputs/vit_class_subtract"
  num_train_epochs: 10
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8

  # Optimization
  learning_rate: 2.0e-5
  weight_decay: 0.01
  warmup_ratio: 0.1

  # Learning rate scheduler
  lr_scheduler_type: "cosine"

  # Evaluation and Saving
  evaluation_strategy: "epoch"
  save_strategy: "epoch"
  save_total_limit: 3
  load_best_model_at_end: true
  metric_for_best_model: "f1"
  greater_is_better: true

  # Logging
  logging_dir: "Experiments/outputs/vit_class_subtract/logs"
  logging_strategy: "steps"
  logging_steps: 10
  report_to: ["wandb"]  # Changed from tensorboard to wandb

  # Training optimizations
  fp16: false  # Set to true if GPU supports it
  dataloader_num_workers: 4
  remove_unused_columns: false

  # Early stopping (DISABLED - training will run for full num_train_epochs)
  # early_stopping_patience: 3
  # early_stopping_threshold: 0.001

# Data Augmentation (during training)
augmentation:
  enabled: true
  random_horizontal_flip: 0.5
  random_rotation: 15
  color_jitter:
    brightness: 0.2
    contrast: 0.2
    saturation: 0.2
    hue: 0.1

# Evaluation Metrics
metrics:
  - "accuracy"
  - "precision"
  - "recall"
  - "f1"
  - "confusion_matrix"

# Inference Configuration
inference:
  batch_size: 16
  device: "cuda"  # or "cpu"

# Paths
paths:
  checkpoint_dir: "Experiments/outputs/vit_class_subtract/checkpoints"
  results_dir: "Experiments/outputs/vit_class_subtract/results"

# System
system:
  seed: 42
  device: "cuda"  # or "cpu"
  num_workers: 4

# Weights & Biases Configuration
wandb:
  project: "eyegaze-vit-classification"
  run_name: null  # Auto-generate if null
  tags:
    - "vit"
    - "dual-image"
    - "eyegaze"
    - "single-vs-competition"
  notes: "ViT training for dual-image eye-gaze classification (Single/Competition/Cooperation)"
  entity: null  # Set your wandb username/team here if needed

# =============================================================================
# Early Fusion ViT - Gaze Heatmap Classification
# =============================================================================

# Model Configuration
model:
  name: "vit_base_patch16_224"
  num_classes: 3
  pretrained: true

  # Fusion mode for dual gaze heatmaps
  # Options: concat, add, subtract, subtract_abs, multiply
  #   - concat: Channel concatenation (6 channels) - requires modified patch_embed
  #   - add: (img_a + img_b) / 2 - captures common features (3 channels)
  #   - subtract: (img_a - img_b) / 2 - captures directional differences (3 channels)
  #   - subtract_abs: |img_a - img_b| - captures symmetric differences (3 channels)
  #   - multiply: normalized(img_a * img_b) - captures overlapping regions (3 channels)
  fusion_mode: "concat"

  # Only used when fusion_mode="concat"
  weight_init_strategy: "duplicate"  # 6-channel weight initialization

  dropout: 0.1

# Data Configuration
data:
  metadata_path: "1_Data/metadata/complete_metadata.json"
  image_base_path: "G:/共用雲端硬碟/CNElab_林佳誼_Gaze/B.GazeImage/01.data/bgOn_heatmapOn_trajOn" # "/home/cnelabai/PycharmProjects/EyeGaze-Multimodal_old/bgOn_heatmapOn_trajOn" on ubuntu
  image_extension: ".jpg"
  image_size: 224

  # Class mapping
  class_names: ["Single", "Competition", "Cooperation"]
  label2id:
    Single: 0
    Competition: 1
    Cooperation: 2
  id2label:
    0: "Single"
    1: "Competition"
    2: "Cooperation"

  # Train/Val split - Fixed by Pair
  split_by: "pair"
  val_pairs: [33, 34, 35, 36, 37, 38, 39, 40]  # 8 pairs for validation
  seed: 42

# Training Configuration
training:
  epochs: 50
  batch_size: 16 #64 on ubuntu
  num_workers: 4

  # Optimizer
  optimizer: "adamw"
  learning_rate: 5.0e-5 # 2.0e-4 on ubuntu
  weight_decay: 0.01

  # LR Scheduler with Warmup
  scheduler: "cosine"
  warmup_epochs: 5

  # Class imbalance handling
  use_weighted_loss: true
  # Weights will be computed from training data distribution

  # Mixed precision
  fp16: true

  # Gradient clipping
  max_grad_norm: 1.0

# Checkpoint Configuration
checkpoint:
  # Note: actual save path = save_dir/{fusion_mode}/
  save_dir: "4_Experiments/runs/gaze_earlyfusion"
  save_every_epochs: 10
  save_best: true
  metric_for_best: "val_f1"
  greater_is_better: true

# Resume Training
resume:
  enabled: false
  checkpoint_path: null  # Set path to resume from specific checkpoint

# Data Augmentation
augmentation:
  train:
    random_horizontal_flip: 0.5
  val:
    # No augmentation for validation
    pass: true

# Evaluation
evaluation:
  eval_every_epochs: 1
  metrics:
    - accuracy
    - precision
    - recall
    - f1
    - confusion_matrix

# Weights & Biases
wandb:
  enabled: true
  project: "Multimodal_Gaze"
  # Note: actual run_name = {run_name}_{fusion_mode}_{timestamp}
  run_name: "early_fusion_vit"
  tags:
    - "early-fusion"
    - "vit"
    - "gaze"
    - "channel-concat"
  notes: "Early Fusion ViT with 6-channel input (dual gaze heatmap concatenation)"
  log_model: false  # Don't upload checkpoints to wandb

# System
system:
  seed: 42
  device: "cuda"
  deterministic: false  # Set true for reproducibility (slower)
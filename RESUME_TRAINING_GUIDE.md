# è¨“ç·´ä¸­æ–·æ¢å¾©æŒ‡å— (Resume Training Guide)

## âœ… å·²å¯¦ç¾çš„åŠŸèƒ½

è¨“ç·´è…³æœ¬ç¾åœ¨å®Œå…¨æ”¯æŒä¸­æ–·å¾Œæ¢å¾©è¨“ç·´ï¼

---

## ğŸ¯ åŠŸèƒ½èªªæ˜

### 1. è‡ªå‹•æª¢æ¸¬æœ€æ–° Checkpoint âœ…
- è¨“ç·´è…³æœ¬æœƒè‡ªå‹•åœ¨è¼¸å‡ºç›®éŒ„ä¸­å°‹æ‰¾æœ€æ–°çš„ checkpoint
- ä½¿ç”¨ `--resume` åƒæ•¸å³å¯è‡ªå‹•æ¢å¾©

### 2. ä¿æŒ Wandb Run é€£çºŒ âœ…
- Resume æ™‚æœƒå˜—è©¦ç¹¼çºŒåŒä¸€å€‹ wandb run
- è¨“ç·´æ›²ç·šä¸æœƒä¸­æ–·ï¼Œä¿æŒé€£çºŒæ€§

### 3. å‘½ä»¤è¡Œæ§åˆ¶ âœ…
- `--resume`: è‡ªå‹•æª¢æ¸¬ä¸¦å¾æœ€æ–° checkpoint æ¢å¾©
- `--checkpoint`: æŒ‡å®šç‰¹å®šçš„ checkpoint è·¯å¾‘

### 4. å–æ¶ˆ Early Stopping âœ…
- å·²ç§»é™¤ early stopping æ©Ÿåˆ¶
- è¨“ç·´æœƒå®Œæ•´é‹è¡Œè¨­å®šçš„ epoch æ•¸

---

## ğŸš€ ä½¿ç”¨æ–¹å¼

### æ–¹æ³• 1: è‡ªå‹•æ¢å¾©ï¼ˆæ¨è–¦ï¼‰

```bash
# æ­£å¸¸è¨“ç·´
python Experiments/scripts/train_vit.py

# è¨“ç·´ä¸­æ–·ï¼ˆCtrl+C æˆ–æ„å¤–ä¸­æ–·ï¼‰
# ... ä¸­æ–· ...

# è‡ªå‹•å¾æœ€æ–° checkpoint æ¢å¾©
python Experiments/scripts/train_vit.py --resume
```

**è¼¸å‡ºç¯„ä¾‹**:
```
INFO - Auto-detected checkpoint: Experiments/outputs/vit_class_subtract/checkpoint-500
INFO - Resuming wandb run: abc123xyz
INFO - Training will resume from checkpoint: checkpoint-500
INFO - Resuming training from: Experiments/outputs/vit_class_subtract/checkpoint-500
```

### æ–¹æ³• 2: æŒ‡å®š Checkpoint

```bash
# å¾ç‰¹å®š checkpoint æ¢å¾©
python Experiments/scripts/train_vit.py \
  --checkpoint Experiments/outputs/vit_class_subtract/checkpoint-500
```

### æ–¹æ³• 3: å¾é ­é–‹å§‹ï¼ˆé è¨­ï¼‰

```bash
# ä¸ä½¿ç”¨ä»»ä½•åƒæ•¸ï¼Œå¾é ­é–‹å§‹è¨“ç·´
python Experiments/scripts/train_vit.py
```

---

## ğŸ“Š Checkpoint çµæ§‹

è¨“ç·´æ™‚æœƒè‡ªå‹•ä¿å­˜ checkpointï¼š

```
Experiments/outputs/vit_class_subtract/
â”œâ”€â”€ checkpoint-100/              # Epoch 1 çµæŸ
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ model.safetensors
â”‚   â”œâ”€â”€ optimizer.pt             # å„ªåŒ–å™¨ç‹€æ…‹
â”‚   â”œâ”€â”€ scheduler.pt             # å­¸ç¿’ç‡èª¿åº¦å™¨
â”‚   â”œâ”€â”€ trainer_state.json       # è¨“ç·´ç‹€æ…‹
â”‚   â””â”€â”€ training_args.bin
â”œâ”€â”€ checkpoint-200/              # Epoch 2 çµæŸ
â”œâ”€â”€ checkpoint-300/              # Epoch 3 çµæŸï¼ˆæœ€æ–°ï¼‰
â””â”€â”€ wandb/                       # Wandb é‹è¡Œæ•¸æ“š
    â””â”€â”€ run-20231029_123456-abc123/
```

**é…ç½®èªªæ˜**:
```yaml
training:
  save_strategy: "epoch"      # æ¯å€‹ epoch ä¿å­˜
  save_total_limit: 3         # åªä¿ç•™æœ€è¿‘ 3 å€‹
```

---

## ğŸ” Resume æ¢å¾©çš„å…§å®¹

ä½¿ç”¨ `--resume` æ™‚ï¼Œä»¥ä¸‹å…§å®¹æœƒå®Œæ•´æ¢å¾©ï¼š

### âœ… æ¨¡å‹ç‹€æ…‹
- æ¨¡å‹æ¬Šé‡ï¼ˆæ‰€æœ‰åƒæ•¸ï¼‰
- åˆ†é¡é ­æ¬Šé‡

### âœ… å„ªåŒ–å™¨ç‹€æ…‹
- Adam å„ªåŒ–å™¨çš„å‹•é‡
- åƒæ•¸çš„ä¸€éšå’ŒäºŒéšçŸ©ä¼°è¨ˆ

### âœ… å­¸ç¿’ç‡èª¿åº¦å™¨
- ç•¶å‰å­¸ç¿’ç‡
- Warmup é€²åº¦
- Cosine decay ç‹€æ…‹

### âœ… è¨“ç·´é€²åº¦
- ç•¶å‰ epoch
- Global step (å·²è¨“ç·´çš„ batch æ•¸)
- æœ€ä½³æŒ‡æ¨™å€¼

### âœ… éš¨æ©Ÿæ•¸ç‹€æ…‹
- PyTorch éš¨æ©Ÿæ•¸ç”Ÿæˆå™¨
- NumPy éš¨æ©Ÿæ•¸ç”Ÿæˆå™¨

### âœ… Wandb é‹è¡Œ
- ç¹¼çºŒåŒä¸€å€‹ run_id
- ä¿æŒè¨“ç·´æ›²ç·šé€£çºŒ

---

## ğŸ“‹ å¸¸è¦‹å ´æ™¯

### å ´æ™¯ 1: è¨“ç·´ä¸­æ‰‹å‹•ä¸­æ–·ï¼ˆCtrl+Cï¼‰

```bash
# è¨“ç·´ä¸­...
python Experiments/scripts/train_vit.py
# è¨“ç·´åˆ° Epoch 5/10ï¼ŒæŒ‰ Ctrl+C ä¸­æ–·

# ç¨å¾Œç¹¼çºŒ
python Experiments/scripts/train_vit.py --resume
# âœ… å¾ Epoch 5 ç¹¼çºŒè¨“ç·´åˆ° Epoch 10
```

### å ´æ™¯ 2: GPU è¨˜æ†¶é«”æº¢å‡º

```bash
# è¨“ç·´å´©æ½°
python Experiments/scripts/train_vit.py
# Out of memory éŒ¯èª¤

# èª¿æ•´ batch size å¾Œç¹¼çºŒ
# ä¿®æ”¹ config: per_device_train_batch_size: 4
python Experiments/scripts/train_vit.py --resume
# âš ï¸ æ³¨æ„ï¼šæ”¹è®Š batch size å¯èƒ½å½±éŸ¿è¨“ç·´å‹•æ…‹
```

### å ´æ™¯ 3: æœå‹™å™¨é‡å•Ÿ/æ–·é›»

```bash
# è¨“ç·´ä¸­æ–·
# ... æœå‹™å™¨é‡å•Ÿ ...

# é‡å•Ÿå¾Œç¹¼çºŒ
python Experiments/scripts/train_vit.py --resume
# âœ… è‡ªå‹•å¾æœ€æ–° checkpoint æ¢å¾©
```

### å ´æ™¯ 4: æƒ³å¾ç‰¹å®š checkpoint é‡æ–°é–‹å§‹

```bash
# ç™¼ç¾ Epoch 5 æ•ˆæœæœ€å¥½ï¼Œæƒ³å¾é‚£è£¡ç¹¼çºŒèª¿æ•´
python Experiments/scripts/train_vit.py \
  --checkpoint Experiments/outputs/vit_class_subtract/checkpoint-500
```

### å ´æ™¯ 5: å®Œå…¨é‡æ–°è¨“ç·´

```bash
# åˆªé™¤èˆŠçš„ checkpoints
rm -rf Experiments/outputs/vit_class_subtract/

# å¾é ­é–‹å§‹
python Experiments/scripts/train_vit.py
```

---

## âš™ï¸ é…ç½®èªªæ˜

### Checkpoint ä¿å­˜ç­–ç•¥

```yaml
training:
  # ä¿å­˜ç­–ç•¥
  save_strategy: "epoch"           # æ¯å€‹ epoch ä¿å­˜
  # save_strategy: "steps"         # æˆ–æ¯ N steps ä¿å­˜
  # save_steps: 500                # steps æ¨¡å¼ä¸‹çš„é–“éš”

  # ä¿å­˜é™åˆ¶
  save_total_limit: 3              # æœ€å¤šä¿ç•™ 3 å€‹ checkpoint

  # æœ€ä½³æ¨¡å‹
  load_best_model_at_end: true     # è¨“ç·´çµæŸè¼‰å…¥æœ€ä½³æ¨¡å‹
  metric_for_best_model: "f1"      # ç”¨æ–¼åˆ¤æ–·æœ€ä½³çš„æŒ‡æ¨™
  greater_is_better: true          # F1 è¶Šå¤§è¶Šå¥½
```

### Early Stoppingï¼ˆå·²ç¦ç”¨ï¼‰

```yaml
# Early stopping (DISABLED)
# early_stopping_patience: 3
# early_stopping_threshold: 0.001
```

ç¾åœ¨è¨“ç·´æœƒé‹è¡Œå®Œæ•´çš„ `num_train_epochs`ï¼Œä¸æœƒæå‰åœæ­¢ã€‚

---

## ğŸ”§ æŠ€è¡“ç´°ç¯€

### è‡ªå‹•æª¢æ¸¬é‚è¼¯

```python
def get_last_checkpoint(output_dir):
    """å°‹æ‰¾æœ€æ–°çš„ checkpoint"""
    checkpoints = [d for d in os.listdir(output_dir)
                   if d.startswith('checkpoint-')]
    if not checkpoints:
        return None
    checkpoints.sort(key=lambda x: int(x.split('-')[-1]))
    return checkpoints[-1]  # è¿”å›ç·¨è™Ÿæœ€å¤§çš„
```

### Wandb Run ID æ¢å¾©

```python
# å¾ checkpoint ç›®éŒ„ä¸­æå– wandb run_id
wandb_run_path = os.path.join(output_dir, 'wandb')
if os.path.exists(wandb_run_path):
    run_dirs = [d for d in os.listdir(wandb_run_path)
                if d.startswith('run-')]
    latest_run = sorted(run_dirs)[-1]
    wandb_id = latest_run.split('-')[-1]
    wandb.init(id=wandb_id, resume="must")
```

---

## ğŸ“ æ—¥èªŒè¼¸å‡º

### Resume æˆåŠŸ

```
2025-10-29 16:30:00 - INFO - Loading configuration from config.yaml
2025-10-29 16:30:01 - INFO - Auto-detected checkpoint: checkpoint-500
2025-10-29 16:30:02 - INFO - Resuming wandb run: abc123xyz
2025-10-29 16:30:03 - INFO - Wandb run initialized: vit-subtract-run-1
2025-10-29 16:30:04 - INFO - Training will resume from checkpoint: checkpoint-500
2025-10-29 16:30:10 - INFO - Resuming training from: checkpoint-500
```

### ç„¡ Checkpointï¼ˆå¾é ­é–‹å§‹ï¼‰

```
2025-10-29 16:30:00 - INFO - Loading configuration from config.yaml
2025-10-29 16:30:01 - INFO - No checkpoint found, starting from scratch
2025-10-29 16:30:02 - INFO - Wandb run initialized: vit-subtract-run-2
2025-10-29 16:30:10 - INFO - Starting training from scratch
```

---

## âš ï¸ æ³¨æ„äº‹é …

### 1. é…ç½®æ–‡ä»¶è®Šæ›´

Resume æ™‚æ‡‰é¿å…æ”¹è®Šï¼š
- âŒ `model_name` (æ¨¡å‹æ¶æ§‹)
- âŒ `num_labels` (åˆ†é¡é¡åˆ¥æ•¸)
- âŒ `concat_mode` (èåˆæ¨¡å¼)
- âš ï¸ `learning_rate` (å¯ä»¥æ”¹ï¼Œä½†æœƒå½±éŸ¿è¨“ç·´)
- âš ï¸ `batch_size` (å¯ä»¥æ”¹ï¼Œä½†ä¸æ¨è–¦)

å¯ä»¥å®‰å…¨æ”¹è®Šï¼š
- âœ… `num_train_epochs` (å»¶é•·è¨“ç·´)
- âœ… `logging_steps` (æ—¥èªŒé »ç‡)
- âœ… `save_total_limit` (ä¿å­˜æ•¸é‡)

### 2. æ•¸æ“šé›†è®Šæ›´

- âŒ ä¸è¦æ”¹è®Šè¨“ç·´æ•¸æ“š
- âŒ ä¸è¦æ”¹è®Š `train_test_split` æ¯”ä¾‹
- âŒ ä¸è¦æ”¹è®Š `random_seed`

### 3. Checkpoint ç®¡ç†

```yaml
save_total_limit: 3  # åªä¿ç•™æœ€è¿‘ 3 å€‹
```

èˆŠçš„ checkpoint æœƒè‡ªå‹•åˆªé™¤ï¼Œæ³¨æ„ï¼š
- å¦‚æœæƒ³ä¿ç•™æŸå€‹ checkpointï¼Œè¤‡è£½åˆ°åˆ¥è™•
- åˆªé™¤ checkpoint å¾Œç„¡æ³•æ¢å¾©

### 4. ç£ç¢Ÿç©ºé–“

æ¯å€‹ checkpoint ç´„ä½”ç”¨ ~350MBï¼ˆViT-baseï¼‰ï¼š
- 3 å€‹ checkpoint â‰ˆ 1GB
- ç¢ºä¿æœ‰è¶³å¤ çš„ç£ç¢Ÿç©ºé–“

---

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å•é¡Œ 1: "No checkpoint found" ä½†ç¢ºå¯¦æœ‰ checkpoint

**åŸå› **: Checkpoint ç›®éŒ„åç¨±ä¸ç¬¦åˆæ ¼å¼

**è§£æ±º**:
```bash
# æª¢æŸ¥ç›®éŒ„åç¨±
ls Experiments/outputs/vit_class_subtract/
# æ‡‰è©²çœ‹åˆ° checkpoint-100, checkpoint-200 ç­‰

# å¦‚æœæ ¼å¼ä¸å°ï¼Œæ‰‹å‹•æŒ‡å®š
python train_vit.py --checkpoint path/to/checkpoint
```

### å•é¡Œ 2: Resume å¾Œ wandb å‰µå»ºäº†æ–°çš„ run

**åŸå› **: ç„¡æ³•æ‰¾åˆ°åŸ wandb run_id

**è§£æ±º**:
- æ­£å¸¸æƒ…æ³æœƒè‡ªå‹•è™•ç†
- å¦‚éœ€æ‰‹å‹•æŒ‡å®šï¼Œä¿®æ”¹ä»£ç¢¼ä¸­çš„ wandb.init()

### å•é¡Œ 3: Resume å¾Œè¨“ç·´å¾ epoch 0 é–‹å§‹

**åŸå› **: Checkpoint å¯èƒ½æå£

**æª¢æŸ¥**:
```bash
# æŸ¥çœ‹ trainer_state.json
cat checkpoint-500/trainer_state.json | grep epoch
```

**è§£æ±º**: ä½¿ç”¨æ›´æ—©çš„ checkpoint

### å•é¡Œ 4: æ”¹äº†é…ç½®å¾Œ resume å‡ºéŒ¯

**åŸå› **: é…ç½®èˆ‡ checkpoint ä¸å…¼å®¹

**è§£æ±º**:
- æ¢å¾©åŸé…ç½®
- æˆ–åˆªé™¤ checkpoint å¾é ­è¨“ç·´

---

## ğŸ“š åƒè€ƒè³‡æ–™

- HuggingFace Trainer: https://huggingface.co/docs/transformers/main_classes/trainer
- Resume Training: https://huggingface.co/docs/transformers/main_classes/trainer#resuming-training
- Wandb Resume: https://docs.wandb.ai/guides/runs/resuming

---

## âœ… æª¢æŸ¥æ¸…å–®

è¨“ç·´å‰ç¢ºèªï¼š
- [ ] æœ‰è¶³å¤ çš„ç£ç¢Ÿç©ºé–“ï¼ˆ> 5GBï¼‰
- [ ] é…ç½®æ–‡ä»¶æ­£ç¢º
- [ ] çŸ¥é“å¦‚ä½•ä½¿ç”¨ `--resume`

Resume å‰ç¢ºèªï¼š
- [ ] Checkpoint å­˜åœ¨
- [ ] é…ç½®æ–‡ä»¶æœªæ”¹è®Šé—œéµåƒæ•¸
- [ ] æ•¸æ“šé›†æœªè®Šæ›´

---

**ğŸ‰ ç¾åœ¨å¯ä»¥æ”¾å¿ƒè¨“ç·´ï¼Œä¸ç”¨æ“”å¿ƒä¸­æ–·äº†ï¼**

## å¿«é€Ÿå‘½ä»¤

```bash
# æ­£å¸¸è¨“ç·´
python Experiments/scripts/train_vit.py

# æ¢å¾©è¨“ç·´ï¼ˆæ¨è–¦ï¼‰
python Experiments/scripts/train_vit.py --resume

# æŒ‡å®š checkpoint
python Experiments/scripts/train_vit.py --checkpoint path/to/checkpoint

# æŸ¥çœ‹å¹«åŠ©
python Experiments/scripts/train_vit.py --help
```

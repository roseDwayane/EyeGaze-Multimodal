# Dual Image Fusion Module

## æ¦‚è¿°

æ­¤æ¨¡çµ„æä¾›å°‡ player1 å’Œ player2 çš„çœ¼å‹•è¿½è¹¤åœ–ç‰‡æ‹¼æ¥ï¼ˆæ°´å¹³æˆ–å‚ç›´ï¼‰çš„åŠŸèƒ½ï¼Œç”¨æ–¼ ViT åœ–ç‰‡åˆ†é¡è¨“ç·´ã€‚

## æ–‡ä»¶èªªæ˜

- **`two_image_fusion.py`**: ä¸»è¦æ¨¡çµ„ï¼ŒåŒ…å« `DualImageDataset` é¡
- **`test_fusion_simple.py`**: ç¨ç«‹æ¸¬è©¦è…³æœ¬ï¼ˆä¸éœ€è¦ HuggingFace datasetsï¼‰
- **`TEST_RESULTS.md`**: æ¸¬è©¦çµæœè©³ç´°å ±å‘Š
- **`test_outputs/`**: æ¸¬è©¦ç”Ÿæˆçš„æ‹¼æ¥åœ–ç‰‡

## å¿«é€Ÿæ¸¬è©¦

### åŸºæœ¬æ¸¬è©¦ï¼ˆæ¨è–¦ï¼‰

```bash
python Data/processed/test_fusion_simple.py --num-samples 5
```

### æ¸¬è©¦å‚ç›´æ‹¼æ¥

```bash
python Data/processed/test_fusion_simple.py --concat-mode vertical --num-samples 10
```

### è‡ªå®šç¾©è·¯å¾‘

```bash
python Data/processed/test_fusion_simple.py \
    --metadata Data/metadata/complete_metadata.json \
    --images Data/raw/Gaze/example \
    --num-samples 20 \
    --concat-mode horizontal
```

## æ¸¬è©¦çµæœ

âœ… **ç‹€æ…‹: æ¸¬è©¦é€šé**

- **æˆåŠŸç‡**: 80% (4/5 samples)
- **å¤±æ•—åŸå› **: 1å€‹æ¨£æœ¬çš„åœ–ç‰‡æª”æ¡ˆä¸åœ¨ example è³‡æ–™å¤¾ä¸­ï¼ˆé æœŸè¡Œç‚ºï¼‰

### ç”Ÿæˆçš„æ‹¼æ¥åœ–ç‰‡

æ‰€æœ‰æ¸¬è©¦åœ–ç‰‡ä¿å­˜åœ¨ `Data/processed/test_outputs/`ï¼š

1. **æ°´å¹³æ‹¼æ¥** (6000 x 1583)
   - `sample_1_Single_horizontal.jpg`
   - `sample_2_Single_horizontal.jpg`
   - `sample_3_Competition_horizontal.jpg`
   - `sample_4_Cooperation_horizontal.jpg`

2. **å‚ç›´æ‹¼æ¥** (3000 x 3166)
   - `sample_1_Single_vertical.jpg`

### æ‹¼æ¥ç¤ºä¾‹

#### æ°´å¹³æ‹¼æ¥ (æ¨è–¦ç”¨æ–¼è¨“ç·´)
```
[Player Image]  +  [Observer Image]  =  [Concatenated]
[3000 x 1583]      [3000 x 1583]        [6000 x 1583]
```

#### å‚ç›´æ‹¼æ¥
```
[Player Image]                           [Concatenated]
[3000 x 1583]     =                     [3000 x 3166]
     +
[Observer Image]
[3000 x 1583]
```

## åŠŸèƒ½ç‰¹æ€§

### âœ… å·²é©—è­‰åŠŸèƒ½

1. **åœ–ç‰‡è¼‰å…¥**: è‡ªå‹•è¼‰å…¥ player1 å’Œ player2 çš„ JPG åœ–ç‰‡
2. **æ°´å¹³æ‹¼æ¥**: å°‡å…©å¼µåœ–ç‰‡å·¦å³æ‹¼æ¥
3. **å‚ç›´æ‹¼æ¥**: å°‡å…©å¼µåœ–ç‰‡ä¸Šä¸‹æ‹¼æ¥
4. **éŒ¯èª¤è™•ç†**: ç•¶åœ–ç‰‡ä¸å­˜åœ¨æ™‚æä¾›æ¸…æ™°çš„è­¦å‘Š
5. **è¼¸å‡ºå“è³ª**: é«˜å“è³ª JPEG è¼¸å‡ºï¼ˆquality=95ï¼‰
6. **çµ±è¨ˆè³‡è¨Š**: æä¾›åƒç´ çµ±è¨ˆè³‡è¨Šï¼ˆå‡å€¼ã€æ¨™æº–å·®ï¼‰

### ğŸ”§ æŠ€è¡“ç´°ç¯€

- **åœ–ç‰‡æ ¼å¼**: JPG, è½‰æ›ç‚º RGB
- **åŸå§‹å°ºå¯¸**: 3000 x 1583 pixels
- **æª”æ¡ˆå¤§å°**: 264-318 KB (é«˜å“è³ªå£“ç¸®)
- **åƒç´ çµ±è¨ˆ**: mean â‰ˆ 80-81, std â‰ˆ 46-47

## ä½¿ç”¨æ–¹å¼

### æ–¹æ³• 1: ç¨ç«‹æ¸¬è©¦ï¼ˆä¸éœ€è¦ HuggingFaceï¼‰

```python
from test_fusion_simple import concat_images

# æ‹¼æ¥å…©å¼µåœ–ç‰‡
img1_path = "Data/raw/Gaze/example/Pair-12-A-Single-EYE_trial01_player.jpg"
img2_path = "Data/raw/Gaze/example/Pair-12-A-Single-EYE_trial01_observer.jpg"

concatenated = concat_images(img1_path, img2_path, concat_mode="horizontal")
concatenated.save("output.jpg")
```

### æ–¹æ³• 2: æ•´åˆåˆ°è¨“ç·´æµç¨‹ï¼ˆéœ€è¦ HuggingFace datasetsï¼‰

```python
from datasets import load_dataset
from transformers import ViTImageProcessor
from Data.processed.two_image_fusion import DualImageDataset

# è¼‰å…¥è³‡æ–™
datasets = load_dataset("json", data_files="Data/metadata/complete_metadata.json", split="train")

# åˆå§‹åŒ– processor
image_processor = ViTImageProcessor.from_pretrained("google/vit-base-patch16-224")

# å‰µå»º dataset
label2id = {"Single": 0, "Competition": 1, "Cooperation": 2}

dataset = DualImageDataset(
    datasets,
    image_processor,
    image_base_path="Data/raw/Gaze/example",
    label2id=label2id,
    concat_mode="horizontal"
)

# ä½¿ç”¨
sample = dataset[0]
print(sample['pixel_values'].shape)  # torch.Size([3, 224, 224])
print(sample['labels'])               # tensor(0)
```

## èˆ‡è¨“ç·´æµç¨‹æ•´åˆ

æ­¤æ¨¡çµ„å·²æ•´åˆåˆ° `Experiments/scripts/train_vit.py` ä¸­ï¼š

```python
# åœ¨è¨“ç·´è…³æœ¬ä¸­
from Data.processed.two_image_fusion import DualImageDataset

train_dataset = DualImageDataset(
    split_datasets['train'],
    image_processor,
    image_base_path,
    label2id,
    concat_mode="horizontal"
)

test_dataset = DualImageDataset(
    split_datasets['test'],
    image_processor,
    image_base_path,
    label2id,
    concat_mode="horizontal"
)
```

## åƒæ•¸èªªæ˜

### `DualImageDataset` é¡

| åƒæ•¸ | é¡å‹ | èªªæ˜ |
|------|------|------|
| `dataset` | HuggingFace Dataset | åŒ…å« metadata çš„ dataset ç‰©ä»¶ |
| `image_processor` | ViTImageProcessor | ViT åœ–ç‰‡è™•ç†å™¨ |
| `image_base_path` | str | åœ–ç‰‡æª”æ¡ˆçš„åŸºç¤è·¯å¾‘ |
| `label2id` | dict | é¡åˆ¥åç¨±åˆ° ID çš„æ˜ å°„ |
| `concat_mode` | str | "horizontal" æˆ– "vertical" |

### `concat_images` å‡½æ•¸

| åƒæ•¸ | é¡å‹ | èªªæ˜ |
|------|------|------|
| `img1_path` | str/Path | ç¬¬ä¸€å¼µåœ–ç‰‡è·¯å¾‘ |
| `img2_path` | str/Path | ç¬¬äºŒå¼µåœ–ç‰‡è·¯å¾‘ |
| `concat_mode` | str | "horizontal" æˆ– "vertical" |

## æ•…éšœæ’é™¤

### å•é¡Œ: ModuleNotFoundError: No module named 'datasets'

**è§£æ±ºæ–¹æ³•**: ä½¿ç”¨ `test_fusion_simple.py` é€²è¡Œæ¸¬è©¦ï¼Œå®ƒä¸éœ€è¦ HuggingFace datasets

```bash
python Data/processed/test_fusion_simple.py
```

### å•é¡Œ: Image file not found

**è§£æ±ºæ–¹æ³•**:
1. æª¢æŸ¥ `image_base_path` æ˜¯å¦æ­£ç¢º
2. ç¢ºèªåœ–ç‰‡æª”åèˆ‡ metadata ä¸­çš„åç¨±ä¸€è‡´
3. ç¢ºèªåœ–ç‰‡ç‚º `.jpg` æ ¼å¼

### å•é¡Œ: PIL.UnidentifiedImageError

**è§£æ±ºæ–¹æ³•**:
1. ç¢ºèªåœ–ç‰‡æª”æ¡ˆæ²’æœ‰æå£
2. æª¢æŸ¥åœ–ç‰‡æ ¼å¼æ˜¯å¦ç‚ºæœ‰æ•ˆçš„ JPEG

## æ•ˆèƒ½è€ƒé‡

- **è¨˜æ†¶é«”ä½¿ç”¨**: æ¯æ¬¡è¼‰å…¥å…©å¼µ 3000x1583 çš„åœ–ç‰‡
- **è™•ç†æ™‚é–“**: æ¯å€‹æ¨£æœ¬ç´„ 0.1-0.2 ç§’
- **å»ºè­°æ‰¹æ¬¡å¤§å°**: 8-16ï¼ˆè¦– GPU è¨˜æ†¶é«”è€Œå®šï¼‰

## ä¸‹ä¸€æ­¥

1. **å®‰è£ä¾è³´** (å¦‚æœéœ€è¦è¨“ç·´):
   ```bash
   pip install datasets scikit-learn
   ```

2. **é‹è¡Œå®Œæ•´æ¸¬è©¦**:
   ```bash
   python Data/processed/test_fusion_simple.py --num-samples 20
   ```

3. **é–‹å§‹è¨“ç·´**:
   ```bash
   python Experiments/scripts/train_vit.py --config Experiments/configs/vit_single_vs_competition.yaml
   ```

## ç›¸é—œæ–‡ä»¶

- ä¸»è¨“ç·´è…³æœ¬: `Experiments/scripts/train_vit.py`
- é…ç½®æ–‡ä»¶: `Experiments/configs/vit_single_vs_competition.yaml`
- ViT æ¨¡å‹: `Models/backbones/vit.py`
- è©•ä¼°æŒ‡æ¨™: `metrics/classification.py`

## è¯çµ¡è³‡è¨Š

å¦‚æœ‰å•é¡Œï¼Œè«‹æŸ¥çœ‹:
- `TEST_RESULTS.md` - è©³ç´°æ¸¬è©¦çµæœ
- `../../QUICKSTART.md` - å®Œæ•´å°ˆæ¡ˆå¿«é€Ÿé–‹å§‹æŒ‡å—
